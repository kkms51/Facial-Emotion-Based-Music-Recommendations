{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API setup\n",
    "SPOTIPY_CLIENT_ID = '-'\n",
    "SPOTIPY_CLIENT_SECRET = '-'\n",
    "SPOTIPY_REDIRECT_URI = 'http://localhost:8888/callback'\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=SPOTIPY_CLIENT_ID,\n",
    "                                               client_secret=SPOTIPY_CLIENT_SECRET,\n",
    "                                               redirect_uri=SPOTIPY_REDIRECT_URI,\n",
    "                                               scope='user-library-read user-top-read playlist-modify-private user-read-recently-played'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex feature mappings\n",
    "emotion_feature_map = {\n",
    "    'happy': {'valence': 0.8, 'energy': 0.8, 'danceability': 0.7, 'tempo': 120},\n",
    "    'sad': {'valence': 0.2, 'energy': 0.3, 'danceability': 0.3, 'tempo': 70},\n",
    "    'angry': {'valence': 0.3, 'energy': 0.9, 'danceability': 0.5, 'tempo': 140},\n",
    "    'neutral': {'valence': 0.5, 'energy': 0.5, 'danceability': 0.5, 'tempo': 100},\n",
    "    'surprise': {'valence': 0.6, 'energy': 0.7, 'danceability': 0.6, 'tempo': 110},\n",
    "    'fear': {'valence': 0.2, 'energy': 0.4, 'danceability': 0.3, 'tempo': 90},\n",
    "    'disgust': {'valence': 0.3, 'energy': 0.6, 'danceability': 0.4, 'tempo': 95}\n",
    "}\n",
    "\n",
    "age_feature_map = {\n",
    "    'young': {'popularity': 80, 'acousticness': 0.2, 'instrumentalness': 0.1, 'loudness': -5},\n",
    "    'adult': {'popularity': 60, 'acousticness': 0.4, 'instrumentalness': 0.3, 'loudness': -8},\n",
    "    'senior': {'popularity': 40, 'acousticness': 0.6, 'instrumentalness': 0.5, 'loudness': -10}\n",
    "}\n",
    "\n",
    "gender_feature_map = {\n",
    "    'Man': {'speechiness': 0.5, 'liveness': 0.4, 'mode': 1},\n",
    "    'Woman': {'speechiness': 0.4, 'liveness': 0.5, 'mode': 0}\n",
    "}\n",
    "\n",
    "def get_age_category(age):\n",
    "    if age < 30:\n",
    "        return 'young'\n",
    "    elif age < 60:\n",
    "        return 'adult'\n",
    "    else:\n",
    "        return 'senior'\n",
    "\n",
    "def get_audio_features(track_ids):\n",
    "    all_features = []\n",
    "    batch_size = 50  # Spotify allows up to 100 tracks per request, but we'll use 50 to be safe\n",
    "\n",
    "    for i in range(0, len(track_ids), batch_size):\n",
    "        batch = track_ids[i:i+batch_size]\n",
    "        try:\n",
    "            features = sp.audio_features(tracks=batch)\n",
    "            all_features.extend([f for f in features if f is not None])\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching audio features for batch {i//batch_size + 1}: {str(e)}\")\n",
    "\n",
    "    return all_features\n",
    "\n",
    "def create_user_profile(emotion, age, gender):\n",
    "    age_category = get_age_category(age)\n",
    "    profile = {}\n",
    "    profile.update(emotion_feature_map.get(emotion, {}))\n",
    "    profile.update(age_feature_map.get(age_category, {}))\n",
    "    profile.update(gender_feature_map.get(gender, {}))\n",
    "    return profile\n",
    "\n",
    "def get_user_listening_history():\n",
    "    recent_tracks = sp.current_user_recently_played(limit=50)\n",
    "    top_tracks_short = sp.current_user_top_tracks(limit=50, time_range='short_term')\n",
    "    top_tracks_medium = sp.current_user_top_tracks(limit=50, time_range='medium_term')\n",
    "    top_tracks_long = sp.current_user_top_tracks(limit=50, time_range='long_term')\n",
    "    \n",
    "    all_tracks = (\n",
    "        [item['track']['id'] for item in recent_tracks['items']] +\n",
    "        [track['id'] for track in top_tracks_short['items']] +\n",
    "        [track['id'] for track in top_tracks_medium['items']] +\n",
    "        [track['id'] for track in top_tracks_long['items']]\n",
    "    )\n",
    "    return list(set(all_tracks))  # Remove duplicates\n",
    "\n",
    "def cluster_tracks(features, n_clusters=5):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(features)\n",
    "    return clusters\n",
    "\n",
    "def reduce_dimensions(features, n_components=3):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "    return reduced_features\n",
    "\n",
    "def get_recommendations(emotion, age, gender):\n",
    "    print(\"Creating user profile...\")\n",
    "    user_profile = create_user_profile(emotion, age, gender)\n",
    "    print(\"User profile created:\", user_profile)\n",
    "\n",
    "    print(\"Getting user listening history...\")\n",
    "    user_tracks = get_user_listening_history()\n",
    "    print(\"User tracks retrieved:\", user_tracks)\n",
    "\n",
    "    # Get audio features for user's tracks\n",
    "    print(\"Getting audio features for user tracks...\")\n",
    "    tracks_features = get_audio_features(user_tracks)\n",
    "    print(\"Audio features retrieved.\")\n",
    "\n",
    "    # Create a feature matrix\n",
    "    feature_names = ['valence', 'energy', 'danceability', 'tempo', 'popularity', 'acousticness', 'instrumentalness', 'loudness', 'speechiness', 'liveness', 'mode']\n",
    "    feature_matrix = np.array([[track.get(feature, 0) for feature in feature_names] for track in tracks_features])\n",
    "    print(\"Feature matrix created:\", feature_matrix)\n",
    "\n",
    "    # Normalize the feature matrix\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_feature_matrix = scaler.fit_transform(feature_matrix)\n",
    "    print(\"Feature matrix normalized.\")\n",
    "\n",
    "    # Reduce dimensions for visualization (if needed)\n",
    "    reduced_features = reduce_dimensions(normalized_feature_matrix)\n",
    "    print(\"Dimensions reduced.\")\n",
    "\n",
    "    # Create user profile vector\n",
    "    user_vector = np.array([[user_profile.get(feature, 0.5) for feature in feature_names]])\n",
    "    normalized_user_vector = scaler.transform(user_vector)\n",
    "    print(\"User profile vector created and normalized:\", normalized_user_vector)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = cosine_similarity(normalized_user_vector, normalized_feature_matrix)[0]\n",
    "    print(\"Cosine similarity calculated:\", similarities)\n",
    "\n",
    "    # Get top 10 most similar tracks\n",
    "    top_similar_indices = similarities.argsort()[-10:][::-1]\n",
    "    top_similar_tracks = [user_tracks[i] for i in top_similar_indices]\n",
    "\n",
    "    print(\"Top similar tracks retrieved:\", top_similar_tracks)\n",
    "\n",
    "    # Get recommendations based on seed tracks and user profile\n",
    "    seed_tracks = top_similar_tracks[:5]  # Use top similar tracks as seed\n",
    "    recommendations = sp.recommendations(seed_tracks=seed_tracks, limit=20,\n",
    "                                         target_valence=user_profile['valence'],\n",
    "                                         target_energy=user_profile['energy'],\n",
    "                                         target_danceability=user_profile['danceability'],\n",
    "                                         target_tempo=user_profile['tempo'])\n",
    "\n",
    "    print(\"Recommendations retrieved.\")\n",
    "    return [track['id'] for track in recommendations['tracks']]\n",
    "\n",
    "\n",
    "def create_playlist(track_ids):\n",
    "    user_id = sp.me()['id']\n",
    "    playlist = sp.user_playlist_create(user_id, 'Advanced Emotion-Age-Gender Based Recommendations', public=False)\n",
    "    sp.user_playlist_add_tracks(user_id, playlist['id'], track_ids)\n",
    "    return playlist['external_urls']['spotify']\n",
    "\n",
    "def capture_image():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    return frame\n",
    "\n",
    "def analyze_facial_features(frame):\n",
    "    print(\"Analyzing facial features...\")\n",
    "    analysis = DeepFace.analyze(frame, actions=['emotion', 'age', 'gender'], enforce_detection=False)\n",
    "    print(\"Facial analysis result:\", analysis)\n",
    "    \n",
    "    # Check if analysis is a list and take the first item if so\n",
    "    if isinstance(analysis, list):\n",
    "        analysis = analysis[0]\n",
    "    \n",
    "    emotion = analysis['dominant_emotion']\n",
    "    age = analysis['age']\n",
    "    gender = analysis['dominant_gender']\n",
    "    \n",
    "    # Additional facial feature analysis\n",
    "    face_features = analysis['region']\n",
    "    face_width = face_features['w']\n",
    "    face_height = face_features['h']\n",
    "    face_ratio = face_width / face_height\n",
    "    \n",
    "    return emotion, age, gender, face_ratio\n",
    "\n",
    "def analyze_and_recommend():\n",
    "    frame = capture_image()\n",
    "    try:\n",
    "        print(\"Analyzing facial features...\")\n",
    "        emotion, age, gender, face_ratio = analyze_facial_features(frame)\n",
    "        print(f\"Facial features analyzed: Emotion: {emotion}, Age: {age}, Gender: {gender}, Face Ratio: {face_ratio:.2f}\")\n",
    "        \n",
    "        # Adjust recommendations based on face ratio (just an example)\n",
    "        if face_ratio > 1.1:\n",
    "            # Wider face, might prefer more energetic music\n",
    "            emotion_feature_map[emotion]['energy'] = min(1.0, emotion_feature_map[emotion].get('energy', 0.5) + 0.1)\n",
    "        elif face_ratio < 0.9:\n",
    "            # Longer face, might prefer calmer music\n",
    "            emotion_feature_map[emotion]['energy'] = max(0.0, emotion_feature_map[emotion].get('energy', 0.5) - 0.1)\n",
    "        \n",
    "        print(\"Getting recommendations...\")\n",
    "        track_ids = get_recommendations(emotion, age, gender)\n",
    "        if not track_ids:\n",
    "            print(\"No recommendations found.\")\n",
    "            return\n",
    "\n",
    "        print(\"Creating playlist...\")\n",
    "        playlist_url = create_playlist(track_ids)\n",
    "        \n",
    "        print(\"Getting additional track information...\")\n",
    "        tracks = sp.tracks(track_ids)['tracks']\n",
    "        genres = set()\n",
    "        for track in tracks:\n",
    "            artist_id = track['artists'][0]['id']\n",
    "            artist_info = sp.artist(artist_id)\n",
    "            genres.update(artist_info.get('genres', []))\n",
    "        \n",
    "        top_genres = ', '.join(list(genres)[:5])  # Top 5 genres\n",
    "        \n",
    "        print(f\"Emotion: {emotion}, Age: {age}, Gender: {gender}\")\n",
    "        print(f\"Face Ratio: {face_ratio:.2f}\")\n",
    "        print(f\"Top Genres: {top_genres}\")\n",
    "        print(f\"Playlist: {playlist_url}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during recommendation process: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_and_analyze_image():\n",
    "    frame = capture_image()\n",
    "    try:\n",
    "        emotion, age, gender, face_ratio = analyze_facial_features(frame)\n",
    "        \n",
    "        # Adjust recommendations based on face ratio (just an example)\n",
    "        if face_ratio > 1.1:\n",
    "            emotion_feature_map[emotion]['energy'] = min(1.0, emotion_feature_map[emotion].get('energy', 0.5) + 0.1)\n",
    "        elif face_ratio < 0.9:\n",
    "            emotion_feature_map[emotion]['energy'] = max(0.0, emotion_feature_map[emotion].get('energy', 0.5) - 0.1)\n",
    "        \n",
    "        # Get recommendations\n",
    "        track_ids = get_recommendations(emotion, age, gender)\n",
    "        if not track_ids:\n",
    "            return frame, \"No recommendations found.\"\n",
    "        \n",
    "        # Create playlist\n",
    "        playlist_url = create_playlist(track_ids)\n",
    "        \n",
    "        # Get additional track information\n",
    "        tracks = sp.tracks(track_ids)['tracks']\n",
    "        genres = set()\n",
    "        for track in tracks:\n",
    "            artist_id = track['artists'][0]['id']\n",
    "            artist_info = sp.artist(artist_id)\n",
    "            genres.update(artist_info.get('genres', []))\n",
    "        \n",
    "        top_genres = ', '.join(list(genres)[:5])  # Top 5 genres\n",
    "        \n",
    "        # Format output\n",
    "        result_text = f\"Emotion: {emotion}\\nAge: {age}\\nGender: {gender}\\nTop Genres: {top_genres}\\nPlaylist: {playlist_url}\"\n",
    "        \n",
    "        return frame, result_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return frame, f\"Error during recommendation process: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing facial features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender: 100%|██████████| 3/3 [00:00<00:00,  6.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facial analysis result: [{'emotion': {'angry': 97.0670223236084, 'disgust': 5.459363023874175e-05, 'fear': 0.051638646982610226, 'happy': 2.2770216688513756, 'sad': 0.6001338362693787, 'surprise': 1.3682682720173034e-05, 'neutral': 0.004115197953069583}, 'dominant_emotion': 'angry', 'region': {'x': 0, 'y': 0, 'w': 640, 'h': 480, 'left_eye': None, 'right_eye': None}, 'face_confidence': 0, 'age': 33, 'gender': {'Woman': 5.925409868359566, 'Man': 94.07459497451782}, 'dominant_gender': 'Man'}]\n",
      "Creating user profile...\n",
      "User profile created: {'valence': 0.3, 'energy': 1.0, 'danceability': 0.5, 'tempo': 140, 'popularity': 60, 'acousticness': 0.4, 'instrumentalness': 0.3, 'loudness': -8, 'speechiness': 0.5, 'liveness': 0.4, 'mode': 1}\n",
      "Getting user listening history...\n",
      "User tracks retrieved: ['5PEZxy0cvFiWc9A2CcWipW', '7lQ8MOhq6IN2w8EYcFNSUk', '5QJMiuwSROC3Kdirx7VBgX', '6GpyfvNqCPGdwWNgmSLp3D', '0WbMK4wrZ1wFSty9F7FCgu', '4JHP2bJv5CZbUJ8D7NcmmG', '5OFlp1fOrfiSXOjw4wuSgy', '2vZxL6vruuBFLlUAVeGTQf', '1SWVDBtw6h3tm9OehOkDhv', '1YMBg7rOjxzbya0fPOYfNX', '6AI3ezQ4o3HUoP6Dhudph3', '1zawRShskhVLqcbDJjhhhL', '3yfqSUWxFvZELEM4PmlwIR', '5b3XJ1pjrHO5JtY2PcTjnI', '3nsFmJNRpy4XwCV1nZuDlc', '7KA4W4McWYRpgf0fWsJZWB', '3kAPZV0L77ikzq9HlCEBIg', '56sxN1yKg1dgOZXBcAHkJG', '3b8GCmdDghis9GH2sKYssj', '7FIWs0pqAYbP91WWM0vlTQ', '7ovUcF5uHTBRzUpB6ZOmvt', '26J3mEBJUhqWEEW7WPWnfb', '0VgkVdmE4gld66l8iyGjgx', '5I8sAY5ll9YWHOwYl0RqTa', '08gzPoSnI1NJgyPpfbTChk', '2zZYe0VgBUAamZ9zTxzE4l', '7ycWLEP1GsNjVvcjawXz3z', '09CnYHiZ5jGT1wr1TXJ9Zt', '1gy4cc7UWZ8hW47SoJkmte', '2x2olWuWXpqjoeE4bO1NFS', '4EWCNWgDS8707fNSZ1oaA5', '60ZhjSRzOrdOd4i2V7Y05g', '6i0V12jOa3mr6uu4WYhUBr', '1pQLlhMZrNxVdx93xDjB4O', '0Lmbke3KNVFXtoH2mMSHCw', '1bjeWoagtHmUKputLVyDxQ', '5uCax9HTNlzGybIStD3vDh', '6KQ0NxrOiD2cuafKilTh9D', '7hrFCoyWwKep7qp1lP4oga', '4vVjPTApwXZwB2H3mBq3ml', '3xkHsmpQCBMytMJNiDf3Ii', '7FGq80cy8juXBCD2nrqdWU', '2vKVrk2WdrVcUvd2bsIsr9', '2OzhQlSqBEmt7hmkYxfT6m', '722NAIXkI6WRNvu9O7JkdH', '3eh51r6rFWAlGQRlHx9QnQ', '2MMh0f4Stbp0xTPUgE7TYg', '06AeBc8cQOJUbkkS0Gi165', '0Ta2fVj5VeLL49IZQ9JCO5', '0aHzinvgHpGssK2AoEoj3I', '0lYBSQXN6rCTvUZvg9S0lU', '0aoCHJS5gnOmXqW2a4hPLV', '15JINEqzVMv3SvJTAXAKED', '0RtFqgQIB655Ae8DUDJYW8', '4qNYl4NkngYRqf6DtTyD9I', '7uXoTBYSzHLZ2kNePXQIuH', '2qSkIjg1o9h3YT9RAgYN75', '4nPX2J3qjIy73uwPlLIARN', '47D6kchIHSqk2jJJ7IsKE7', '6dOtVTDdiauQNBQEDOtlAB', '1vNlDf9jgcCnCMukMwUZso', '0fX4oNGBWO3dSGUZcVdVV2', '0nbXyq5TXYPCO7pr3N8S4I', '0UFDKFqW2oGspYeYqo9wjA', '15z7G1timzbpHEKfmBkW8C', '3S6M5oUNQ9gBnI76nYJQfx', '6Ozh9Ok6h4Oi1wUSLtBseN', '0jcw8cJf3TNMZN0BXlueML', '7KXjTSCq5nL1LoYtL7XAwS', '0QzuaeCEEOV40Pn7IvKEny', '4xhsWYTOGcal8zt0J161CU', '4iYRa2btalAzPZoSYfROqF', '26RFoBzKs36gTlbJCmtsFa', '6bdp22y3mEdzBBx4u5p2jt', '1d26TVoQ31YSZQpRjNrELW', '7x9aauaA9cu6tyfpHnqDLo', '4VUwkH455At9kENOfzTqmF', '64Z5S2oDnFP6b8AR9g3OmG', '7ipqVwkp2MhZv0Ojzqy1NV', '6WzRpISELf3YglGAh7TXcG', '2JCH7N4ppRJxCyY1Tee62W', '1MXtcAN5xKKOx0FhJYxESp', '47N81NMkB488fuOwOC3Oip', '60SdxE8apGAxMiRrpbmLY0', '5UeXKnZX5zsozzV2riXTI8', '3yapR7DctB2WtbmXkHHviC', '2ox0MmkQKtPHdAQK7WLmnv', '5bSp6gD3DffZwOvWPOeqEJ', '5eoikvtRssJ8DQu22KTVCb', '6jlG8gBPNAgBgoivw2Ig09', '7w5KxWmWFynsuznG58lmx7', '2HYFX63wP3otVIvopRS99Z', '4rXLjWdF2ZZpXCVTfWcshS', '3qhlB30KknSejmIvZZLjOD', '78QR3Wp35dqAhFEc2qAGjE', '51ZQ1vr10ffzbwIjDCwqm4', '7iXF2W9vKmDoGAhlHdpyIa', '3yW45dYn9d0FPHgSyN5vjb', '2JzFbgbD6cc6E0YSBAAGeY', '176FMSjsr5kR3Ytma1ZiNg', '0zius9760GMm2AZD4kAB9q', '0gmbgwZ8iqyMPmXefof8Yf', '51eSHglvG1RJXtL3qI5trr', '6I3mqTwhRpn34SLVafSH7G', '0hKtu53OlIFXVuYkZwcn3o', '1LxQxX0ce4Q2jmlqdiPIUX', '2rQBSbrgyiECCAx8U1Dcfj', '3LtpKP5abr2qqjunvjlX5i', '1si6omu7DE4Lbe8XwQdUlw', '1AfFUID69eG8hOkkc3asNM', '07oO1U722crtVcavi6frX6', '6IZvVAP7VPPnsGX6bvgkqg', '6NCd68XTktl59lixmE3kWN', '2kQuhkFX7uSVepCD3h29g5', '5bBUDJUfGcG7eFy3Bf4fXv', '75dDRiGlTFi5vnLX0w9qIp']\n",
      "Getting audio features for user tracks...\n",
      "Audio features retrieved.\n",
      "Feature matrix created: [[0.177  0.328  0.269  ... 0.0413 0.902  1.    ]\n",
      " [0.662  0.669  0.908  ... 0.0738 0.237  1.    ]\n",
      " [0.44   0.319  0.633  ... 0.898  0.265  1.    ]\n",
      " ...\n",
      " [0.925  0.741  0.939  ... 0.0471 0.107  0.    ]\n",
      " [0.686  0.524  0.85   ... 0.204  0.114  0.    ]\n",
      " [0.369  0.739  0.598  ... 0.0376 0.742  1.    ]]\n",
      "Feature matrix normalized.\n",
      "Dimensions reduced.\n",
      "User profile vector created and normalized: [[ 0.2517537   1.0396927   0.48044434  0.4940099  60.          0.44377708\n",
      "   0.91463415  0.56667953  0.51333696  0.37779672  1.        ]]\n",
      "Cosine similarity calculated: [0.0239163  0.02639027 0.024387   0.02840972 0.01971453 0.02803177\n",
      " 0.02682218 0.02683592 0.02228342 0.02797154 0.02532441 0.02631489\n",
      " 0.01948414 0.02571243 0.02560257 0.02690171 0.02658764 0.02774921\n",
      " 0.024479   0.02309913 0.02832509 0.01896983 0.02749214 0.0293907\n",
      " 0.02807802 0.02029649 0.02278092 0.03059384 0.02744798 0.02694015\n",
      " 0.02108783 0.01692468 0.01806205 0.02792824 0.02126021 0.02790912\n",
      " 0.02655827 0.02605441 0.02829561 0.02813571 0.02722717 0.0241122\n",
      " 0.02744462 0.02570813 0.0226557  0.02802424 0.02786279 0.02169215\n",
      " 0.02675657 0.0183423  0.0276296  0.02446901 0.02904046 0.02817151\n",
      " 0.02208096 0.02472552 0.0274252  0.02300405 0.02903258 0.02841735\n",
      " 0.02777236 0.02859089 0.02057845 0.02893557 0.0218518  0.02587346\n",
      " 0.02824714 0.02299243 0.02107698 0.02585631 0.02519677 0.02916679\n",
      " 0.02903516 0.02634926 0.02439767 0.02714435 0.02842814 0.02409167\n",
      " 0.02719355 0.02661555 0.02679721 0.01901579 0.02725287 0.02322495\n",
      " 0.02182209 0.02457716 0.02960016 0.01811538 0.02756678 0.02520686\n",
      " 0.0274808  0.0210091  0.02246468 0.02431644 0.02301776 0.02787988\n",
      " 0.0271156  0.02818384 0.02288718 0.01903793 0.01948772 0.02759962\n",
      " 0.02721942 0.02917332 0.020028   0.02880312 0.02593588 0.02680322\n",
      " 0.02701239 0.02742844 0.02613394 0.02193026 0.02494352 0.02086008\n",
      " 0.02098714 0.02851263]\n",
      "Top similar tracks retrieved: ['09CnYHiZ5jGT1wr1TXJ9Zt', '2ox0MmkQKtPHdAQK7WLmnv', '5I8sAY5ll9YWHOwYl0RqTa', '6I3mqTwhRpn34SLVafSH7G', '4iYRa2btalAzPZoSYfROqF', '15JINEqzVMv3SvJTAXAKED', '26RFoBzKs36gTlbJCmtsFa', '47D6kchIHSqk2jJJ7IsKE7', '0UFDKFqW2oGspYeYqo9wjA', '1LxQxX0ce4Q2jmlqdiPIUX']\n",
      "Recommendations retrieved.\n"
     ]
    }
   ],
   "source": [
    "# Define Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=capture_and_analyze_image,\n",
    "    inputs=None,\n",
    "    outputs=[\"image\", \"text\"],\n",
    "    title=\"Facial Emotion-Based Music Recommendations\",\n",
    "    description=\"Capture your image to get personalized music recommendations based on your facial expression.\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
